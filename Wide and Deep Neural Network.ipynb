{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3123e6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fff9f2",
   "metadata": {},
   "source": [
    "This type of neural network connects all or part of the inputs directly to the output layer. This architecture is useful for a neural network to learn both patterns (using the deep path) and more simple rules (through the short path). In contrast to a regular MLP that simply forces all the data to flow throught the full stack of layers thus, causing simple patterns could be distorted by this sequence of transformations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea169c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 23:03:47.349803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:47.349818: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2835c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba708c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81e6e4",
   "metadata": {},
   "source": [
    "# Building Model with Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc8d3b",
   "metadata": {},
   "source": [
    "The Input layer specifies the kind of input the model will get including the shape and dtype. Then two dense layers each with 30 neurons using the ReLU activation function. Then a Concatenate layer that concatenates the input and the output of the 2nd hidden layer. This Concatenate layer essentially combines the Deep and Wide networks. Then an output layer with only one neuron as we are predicting a value. Then we define the model specifying the inputs and outputs to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6398b",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22121d",
   "metadata": {},
   "source": [
    "Steps: compile, train, evaluate, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f49610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compile\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "# 2. Train\n",
    "history = model.fit(X_train, y_train, epochs = 15,\n",
    "                   validation_data = (X_valid, y_valid))\n",
    "\n",
    "# 3. Evaluate\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take square root of loss\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68221c",
   "metadata": {},
   "source": [
    "## Same Model with Different Subset of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6eaa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 23:03:53.721112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 23:03:53.721541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:03:53.721881: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-08 23:03:53.722291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name=\"wide input\")\n",
    "input_B = keras.layers.Input(shape = [6], name=\"deep input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name = \"output\")(concat)\n",
    "model_2 = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c3e70",
   "metadata": {},
   "source": [
    "For this we chose input_A to be the wide input taking up 5 features, and the input that gets passed through the deep channel of the network contains 6 feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd20efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           210         ['deep input[0][0]']             \n",
      "                                                                                                  \n",
      " wide input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 35)           0           ['wide input[0][0]',             \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb2e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now when calling the fit method we need to pass a pair of matrices, one per input\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd8e861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "363/363 [==============================] - 1s 987us/step - loss: 2.2381 - val_loss: 1.1947\n",
      "Epoch 2/15\n",
      "363/363 [==============================] - 0s 528us/step - loss: 1.0060 - val_loss: 0.8321\n",
      "Epoch 3/15\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.7777 - val_loss: 0.7043\n",
      "Epoch 4/15\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.7020 - val_loss: 0.6544\n",
      "Epoch 5/15\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.6595 - val_loss: 0.6194\n",
      "Epoch 6/15\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.6296 - val_loss: 0.5949\n",
      "Epoch 7/15\n",
      "363/363 [==============================] - 0s 581us/step - loss: 0.6048 - val_loss: 0.5720\n",
      "Epoch 8/15\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.5863 - val_loss: 0.5564\n",
      "Epoch 9/15\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.5700 - val_loss: 0.5394\n",
      "Epoch 10/15\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.5563 - val_loss: 0.5292\n",
      "Epoch 11/15\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.5449 - val_loss: 0.5167\n",
      "Epoch 12/15\n",
      "363/363 [==============================] - 0s 567us/step - loss: 0.5349 - val_loss: 0.5075\n",
      "Epoch 13/15\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.5266 - val_loss: 0.5028\n",
      "Epoch 14/15\n",
      "363/363 [==============================] - 0s 596us/step - loss: 0.5203 - val_loss: 0.4943\n",
      "Epoch 15/15\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.5146 - val_loss: 0.4900\n",
      "162/162 [==============================] - 0s 340us/step - loss: 10064.5586\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# 1. Compile\n",
    "model_2.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "# 2. Train\n",
    "history = model_2.fit((X_train_A, X_train_B), y_train, epochs = 15,\n",
    "                   validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "# 3. Evaluate\n",
    "mse_test = model_2.evaluate((X_test_A, X_test_B), y_test)\n",
    "\n",
    "# 4. Predict\n",
    "y_preds = model_2.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b4b94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.32227366716725"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
